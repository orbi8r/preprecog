{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c891f76",
   "metadata": {},
   "source": [
    "# Merge Parquet Files\n",
    "\n",
    "Concatenates the three class parquet files (Class 1 Human, Class 2 Standard AI, Class 3 Imposter AI) into a single `data.parquet` in the top-level `data/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
    "\n",
    "def find_file(rel_path):\n",
    "    for base in candidates:\n",
    "        p = base.joinpath(rel_path)\n",
    "        if p.exists():\n",
    "            return p.resolve()\n",
    "    return None\n",
    "\n",
    "def read_parquet_safely(rel_path, label):\n",
    "    p = find_file(rel_path)\n",
    "    if p is None:\n",
    "        print(f\"{label} not found at expected locations: {rel_path}\")\n",
    "        return pd.DataFrame(), None\n",
    "    try:\n",
    "        df = pd.read_parquet(p)\n",
    "        print(f\"Read {len(df)} rows from {label} ({p})\")\n",
    "        return df, p\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {label} at {p}: {e}\")\n",
    "        return pd.DataFrame(), p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf77bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Read 500 rows from human_class1.parquet (W:\\Programming\\PKOG\\preprecog\\data\\data_human\\processed\\human_class1.parquet)\n"
     ]
    }
   ],
   "source": [
    "# Read human_class1.parquet\n",
    "human_rel = os.path.join('data_human', 'processed', 'human_class1.parquet')\n",
    "df_human, human_path = read_parquet_safely(human_rel, 'human_class1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7417fd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Read 504 rows from ai_class2.parquet (W:\\Programming\\PKOG\\preprecog\\data\\data_ai\\processed\\ai_class2.parquet)\n"
     ]
    }
   ],
   "source": [
    "# Read ai_class2.parquet\n",
    "ai2_rel = os.path.join('data_ai', 'processed', 'ai_class2.parquet')\n",
    "df_ai2, ai2_path = read_parquet_safely(ai2_rel, 'ai_class2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5615aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Read 504 rows from ai_class3.parquet (W:\\Programming\\PKOG\\preprecog\\data\\data_ai\\processed\\ai_class3.parquet)\n"
     ]
    }
   ],
   "source": [
    "# Read ai_class3.parquet\n",
    "ai3_rel = os.path.join('data_ai', 'processed', 'ai_class3.parquet')\n",
    "df_ai3, ai3_path = read_parquet_safely(ai3_rel, 'ai_class3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Dropped 'origin_ref' column from merged data\n",
      "✅ Wrote 1508 total rows to W:\\Programming\\PKOG\\preprecog\\data\\data.parquet\n",
      "Breakdown:\n",
      " - human_class1.parquet: 500\n",
      " - ai_class2.parquet: 504\n",
      " - ai_class3.parquet: 504\n"
     ]
    }
   ],
   "source": [
    "source_paths = [p for p in (human_path, ai2_path, ai3_path) if p is not None]\n",
    "if source_paths:\n",
    "    data_root = source_paths[0].parents[2]\n",
    "else:\n",
    "    data_root = Path.cwd()\n",
    "\n",
    "out_path = data_root.joinpath('data.parquet')\n",
    "\n",
    "frames = []\n",
    "if not df_human.empty: frames.append(df_human)\n",
    "if not df_ai2.empty: frames.append(df_ai2)\n",
    "if not df_ai3.empty: frames.append(df_ai3)\n",
    "\n",
    "if not frames:\n",
    "    print(\"No dataframes read. Nothing to write.\")\n",
    "else:\n",
    "    df_combined = pd.concat(frames, ignore_index=True)\n",
    "    if 'origin_ref' in df_combined.columns:\n",
    "        df_combined = df_combined.drop(columns=['origin_ref'])\n",
    "        print(\"Dropped 'origin_ref' column from merged data\")\n",
    "    df_combined.to_parquet(out_path)\n",
    "    print(f\"Wrote {len(df_combined)} total rows to {out_path}\")\n",
    "    print(f\" - human_class1: {len(df_human)}\")\n",
    "    print(f\" - ai_class2: {len(df_ai2)}\")\n",
    "    print(f\" - ai_class3: {len(df_ai3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
