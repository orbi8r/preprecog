{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db53bc47",
   "metadata": {},
   "source": [
    "# Lexical Richness\n",
    "TTR, Hapax Legomena, MTLD, and sentence length std dev across the dataset by class/author/topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add4d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "WORD_RE = re.compile(r\"\\b\\w+\\b\", flags=re.UNICODE)\n",
    "\n",
    "def tokenize(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return [w.lower() for w in WORD_RE.findall(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a578105",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f6e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read merged data.parquet (W:\\Programming\\PKOG\\preprecogclean\\data\\data.parquet) with 1508 rows\n"
     ]
    }
   ],
   "source": [
    "candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
    "\n",
    "def find_path(rel):\n",
    "    for base in candidates:\n",
    "        p = base.joinpath(rel)\n",
    "        if p.exists():\n",
    "            return p.resolve()\n",
    "    return None\n",
    "\n",
    "merged_path = find_path(Path('data').joinpath('data.parquet'))\n",
    "if merged_path:\n",
    "    df = pd.read_parquet(merged_path)\n",
    "    print(f\"Read merged data.parquet ({merged_path}) with {len(df)} rows\")\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "    print(\"No data available to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaab2de",
   "metadata": {},
   "source": [
    "## Preprocessing & Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4423b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized grouping columns: author_key, topic_key, class_key\n"
     ]
    }
   ],
   "source": [
    "if not df.empty:\n",
    "    def extract_author(fc):\n",
    "        if isinstance(fc, dict):\n",
    "            return fc.get('author') or fc.get('persona_mimicked') or fc.get('persona')\n",
    "        return None\n",
    "\n",
    "    df['author_key'] = df['feature_cache'].apply(extract_author)\n",
    "    df['topic_key'] = df['topic'].astype(str)\n",
    "    df['class_key'] = df['class']\n",
    "    print(\"Normalized grouping columns: author_key, topic_key, class_key\")\n",
    "else:\n",
    "    print(\"No dataframe to normalize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09ffcb",
   "metadata": {},
   "source": [
    "## Type-Token Ratio\n",
    "TTR = unique types / total tokens. Simple vocabulary variety measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32371e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token_ratio(tokens):\n",
    "    N = len(tokens)\n",
    "    if N == 0:\n",
    "        return 0.0\n",
    "    return len(set(tokens)) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91755b",
   "metadata": {},
   "source": [
    "## Hapax Legomena\n",
    "Words appearing exactly once in a 5000-word window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b365e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hapax_in_sample(tokens, sample_size=5000):\n",
    "    N = len(tokens)\n",
    "    if N == 0:\n",
    "        return 0\n",
    "    if N <= sample_size:\n",
    "        sample = tokens\n",
    "    else:\n",
    "        # sample contiguous window to preserve some local structure\n",
    "        start = random.randint(0, N - sample_size)\n",
    "        sample = tokens[start:start+sample_size]\n",
    "    freq = Counter(sample)\n",
    "    return sum(1 for w,c in freq.items() if c == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a472df",
   "metadata": {},
   "source": [
    "## MTLD\n",
    "Avg length of sequential word strings maintaining TTR >= 0.72. More robust to text length than raw TTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11bbfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtld_calc(tokens, ttr_threshold=0.72):\n",
    "    # Helper single pass\n",
    "    def mtld_single_pass(token_list):\n",
    "        factor_count = 0\n",
    "        token_count = 0\n",
    "        types = set()\n",
    "        for w in token_list:\n",
    "            token_count += 1\n",
    "            types.add(w)\n",
    "            ttr = len(types) / token_count\n",
    "            if ttr <= ttr_threshold:\n",
    "                factor_count += 1\n",
    "                token_count = 0\n",
    "                types = set()\n",
    "        # residual\n",
    "        if token_count > 0:\n",
    "            ttr = len(types) / token_count if token_count else 0\n",
    "            partial = (1 - ttr) / (1 - ttr_threshold) if (1 - ttr_threshold) != 0 else 0\n",
    "            factor_count += partial\n",
    "        return (len(token_list) / factor_count) if factor_count != 0 else float('inf')\n",
    "\n",
    "    if not tokens:\n",
    "        return 0.0\n",
    "    forward = mtld_single_pass(tokens)\n",
    "    backward = mtld_single_pass(list(reversed(tokens)))\n",
    "    return (forward + backward) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91ec19",
   "metadata": {},
   "source": [
    "## Sentence Length Std Dev\n",
    "Captures rhythmic variety in sentence construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309aa6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_length_std(text):\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt', quiet=True)\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    if not sents:\n",
    "        return 0.0\n",
    "    lengths = [len(tokenize(s)) for s in sents]\n",
    "    if not lengths:\n",
    "        return 0.0\n",
    "    mean = sum(lengths)/len(lengths)\n",
    "    var = sum((l-mean)**2 for l in lengths)/len(lengths)\n",
    "    return math.sqrt(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5c6c2",
   "metadata": {},
   "source": [
    "## Compute metrics per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a00565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### By Class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_types</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Hapax_5k</th>\n",
       "      <th>MTLD</th>\n",
       "      <th>SentLenStd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class_1</th>\n",
       "      <td>82503</td>\n",
       "      <td>9229</td>\n",
       "      <td>0.111863</td>\n",
       "      <td>986</td>\n",
       "      <td>71.240906</td>\n",
       "      <td>15.787400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_2</th>\n",
       "      <td>80624</td>\n",
       "      <td>5016</td>\n",
       "      <td>0.062215</td>\n",
       "      <td>737</td>\n",
       "      <td>117.875977</td>\n",
       "      <td>7.659899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_3</th>\n",
       "      <td>82120</td>\n",
       "      <td>7315</td>\n",
       "      <td>0.089077</td>\n",
       "      <td>999</td>\n",
       "      <td>75.140273</td>\n",
       "      <td>12.096795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_tokens  n_types       TTR  Hapax_5k        MTLD  SentLenStd\n",
       "group                                                                 \n",
       "class_1     82503     9229  0.111863       986   71.240906   15.787400\n",
       "class_2     80624     5016  0.062215       737  117.875977    7.659899\n",
       "class_3     82120     7315  0.089077       999   75.140273   12.096795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### By Author\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_types</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Hapax_5k</th>\n",
       "      <th>MTLD</th>\n",
       "      <th>SentLenStd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash</th>\n",
       "      <td>73048</td>\n",
       "      <td>6600</td>\n",
       "      <td>0.090352</td>\n",
       "      <td>896</td>\n",
       "      <td>109.221087</td>\n",
       "      <td>11.317308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-2.5-flash-lite</th>\n",
       "      <td>56711</td>\n",
       "      <td>5436</td>\n",
       "      <td>0.095854</td>\n",
       "      <td>944</td>\n",
       "      <td>91.919715</td>\n",
       "      <td>8.883763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini-3-flash-preview</th>\n",
       "      <td>32985</td>\n",
       "      <td>4319</td>\n",
       "      <td>0.130938</td>\n",
       "      <td>737</td>\n",
       "      <td>67.053886</td>\n",
       "      <td>9.004546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russell</th>\n",
       "      <td>20837</td>\n",
       "      <td>2052</td>\n",
       "      <td>0.098479</td>\n",
       "      <td>507</td>\n",
       "      <td>55.727864</td>\n",
       "      <td>14.086077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bacon</th>\n",
       "      <td>20583</td>\n",
       "      <td>3954</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>1012</td>\n",
       "      <td>74.282385</td>\n",
       "      <td>17.797279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>20568</td>\n",
       "      <td>3652</td>\n",
       "      <td>0.177557</td>\n",
       "      <td>993</td>\n",
       "      <td>86.468636</td>\n",
       "      <td>13.604208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emerson</th>\n",
       "      <td>20515</td>\n",
       "      <td>4375</td>\n",
       "      <td>0.213259</td>\n",
       "      <td>1060</td>\n",
       "      <td>76.299866</td>\n",
       "      <td>15.928087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        n_tokens  n_types       TTR  Hapax_5k        MTLD  \\\n",
       "group                                                                       \n",
       "gemini-2.5-flash           73048     6600  0.090352       896  109.221087   \n",
       "gemini-2.5-flash-lite      56711     5436  0.095854       944   91.919715   \n",
       "gemini-3-flash-preview     32985     4319  0.130938       737   67.053886   \n",
       "Russell                    20837     2052  0.098479       507   55.727864   \n",
       "Bacon                      20583     3954  0.192100      1012   74.282385   \n",
       "James                      20568     3652  0.177557       993   86.468636   \n",
       "Emerson                    20515     4375  0.213259      1060   76.299866   \n",
       "\n",
       "                        SentLenStd  \n",
       "group                               \n",
       "gemini-2.5-flash         11.317308  \n",
       "gemini-2.5-flash-lite     8.883763  \n",
       "gemini-3-flash-preview    9.004546  \n",
       "Russell                  14.086077  \n",
       "Bacon                    17.797279  \n",
       "James                    13.604208  \n",
       "Emerson                  15.928087  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### By Topic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_types</th>\n",
       "      <th>TTR</th>\n",
       "      <th>Hapax_5k</th>\n",
       "      <th>MTLD</th>\n",
       "      <th>SentLenStd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>General Philosophy</th>\n",
       "      <td>71054</td>\n",
       "      <td>7092</td>\n",
       "      <td>0.099811</td>\n",
       "      <td>953</td>\n",
       "      <td>83.603890</td>\n",
       "      <td>13.586838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethics &amp; Conduct</th>\n",
       "      <td>62400</td>\n",
       "      <td>7337</td>\n",
       "      <td>0.117580</td>\n",
       "      <td>642</td>\n",
       "      <td>88.477273</td>\n",
       "      <td>11.610807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mind &amp; Knowledge</th>\n",
       "      <td>42710</td>\n",
       "      <td>4254</td>\n",
       "      <td>0.099602</td>\n",
       "      <td>628</td>\n",
       "      <td>73.345592</td>\n",
       "      <td>10.540558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truth &amp; Reality</th>\n",
       "      <td>33776</td>\n",
       "      <td>3977</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>772</td>\n",
       "      <td>77.142748</td>\n",
       "      <td>10.757413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion &amp; Spirit</th>\n",
       "      <td>20653</td>\n",
       "      <td>3674</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>950</td>\n",
       "      <td>92.773029</td>\n",
       "      <td>12.086096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Society &amp; Politics</th>\n",
       "      <td>14654</td>\n",
       "      <td>3265</td>\n",
       "      <td>0.222806</td>\n",
       "      <td>950</td>\n",
       "      <td>87.777986</td>\n",
       "      <td>14.681663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_tokens  n_types       TTR  Hapax_5k       MTLD  \\\n",
       "group                                                                  \n",
       "General Philosophy     71054     7092  0.099811       953  83.603890   \n",
       "Ethics & Conduct       62400     7337  0.117580       642  88.477273   \n",
       "Mind & Knowledge       42710     4254  0.099602       628  73.345592   \n",
       "Truth & Reality        33776     3977  0.117746       772  77.142748   \n",
       "Religion & Spirit      20653     3674  0.177892       950  92.773029   \n",
       "Society & Politics     14654     3265  0.222806       950  87.777986   \n",
       "\n",
       "                    SentLenStd  \n",
       "group                           \n",
       "General Philosophy   13.586838  \n",
       "Ethics & Conduct     11.610807  \n",
       "Mind & Knowledge     10.540558  \n",
       "Truth & Reality      10.757413  \n",
       "Religion & Spirit    12.086096  \n",
       "Society & Politics   14.681663  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df.empty:\n",
    "    print(\"No data to analyze\")\n",
    "else:\n",
    "    random.seed(42)\n",
    "\n",
    "    def metrics_for_series(series_texts):\n",
    "        all_text = \" \".join(series_texts)\n",
    "        tokens = tokenize(all_text)\n",
    "        return {\n",
    "            'n_tokens': len(tokens),\n",
    "            'n_types': len(set(tokens)),\n",
    "            'TTR': type_token_ratio(tokens),\n",
    "            'Hapax_5k': hapax_in_sample(tokens, sample_size=5000),\n",
    "            'MTLD': mtld_calc(tokens),\n",
    "            'SentLenStd': sentence_length_std(all_text)\n",
    "        }\n",
    "\n",
    "    class_metrics = []\n",
    "    for cls, grp in df.groupby('class_key'):\n",
    "        m = metrics_for_series(grp['text'].tolist())\n",
    "        m['group'] = f'class_{cls}'\n",
    "        class_metrics.append(m)\n",
    "    df_class_metrics = pd.DataFrame(class_metrics).set_index('group')\n",
    "    print(\"\\n### By Class\")\n",
    "    display(df_class_metrics)\n",
    "\n",
    "    author_metrics = []\n",
    "    for auth, grp in df.groupby('author_key'):\n",
    "        m = metrics_for_series(grp['text'].tolist())\n",
    "        m['group'] = str(auth)\n",
    "        author_metrics.append(m)\n",
    "    df_author_metrics = pd.DataFrame(author_metrics).set_index('group')\n",
    "    print(\"\\n### By Author\")\n",
    "    display(df_author_metrics.sort_values('n_tokens', ascending=False).head(50))\n",
    "\n",
    "    topic_metrics = []\n",
    "    for tp, grp in df.groupby('topic_key'):\n",
    "        m = metrics_for_series(grp['text'].tolist())\n",
    "        m['group'] = str(tp)\n",
    "        topic_metrics.append(m)\n",
    "    df_topic_metrics = pd.DataFrame(topic_metrics).set_index('group')\n",
    "    print(\"\\n### By Topic\")\n",
    "    display(df_topic_metrics.sort_values('n_tokens', ascending=False).head(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
