{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358a3f43",
   "metadata": {},
   "source": [
    "# The Genetic Algorithm: Evolving AI Text Past Detection\n",
    "\n",
    "## The Adversarial Experiment\n",
    "\n",
    "Can we **evolve** a paragraph of AI-generated text until our best classifier labels it as \"Human\"?\n",
    "\n",
    "This notebook implements a **Genetic Algorithm (GA)** where:\n",
    "- **Chromosome**: A paragraph of text (the phenotype is the text itself)\n",
    "- **Fitness Function**: P(Human) from our Statistician XGBoost model (26 features, AUC 0.9791)\n",
    "- **Mutation Operator**: Gemini API with **feature-guided** rewriting prompts\n",
    "- **Selection**: Elitism â€” keep the top survivors, discard the rest\n",
    "- **Target**: P(Human) > 95%\n",
    "\n",
    "## Why Feature-Guided Mutations?\n",
    "\n",
    "Unlike random mutations, our GA exploits knowledge of **what the detector looks for**:\n",
    "\n",
    "| Feature | Human Mean | AI Mean | What to Fix |\n",
    "|---------|-----------|---------|-------------|\n",
    "| `sent_len_std` | 13.13 | 6.46 | Vary sentence lengths wildly |\n",
    "| `fk_grade` | ~14 | ~11 | Mix complex and simple sentences |\n",
    "| `punct_semicolon` | 2.46/1k | 0.63/1k | Use semicolons to join thoughts |\n",
    "| `punct_apos` | 1.97/1k | 0.53/1k | Use contractions (don't, can't) |\n",
    "| `mtld` | 72.83 | 119.27 | Repeat key terms naturally |\n",
    "\n",
    "Each generation targets the **most AI-like features** in the current best candidate.\n",
    "\n",
    "## API Budget\n",
    "\n",
    "With a 20 requests/day Gemini limit, we're conservative:\n",
    "- **1 call** for initial population (batched â€” 5 variants in 1 request)\n",
    "- **1 call per generation** for mutations (batched)\n",
    "- **5 generations** = **6 total API calls**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75daef52",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cf1eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Ensure UTF-8 for Windows\n",
    "try:\n",
    "    sys.stdout.reconfigure(encoding='utf-8')\n",
    "    sys.stderr.reconfigure(encoding='utf-8')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"\\u2713 Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3115a",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Load API credentials and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddeaef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded .env from: w:\\Programming\\PKOG\\preprecog\\.env\n",
      "âœ“ Gemini client ready (model: gemini-2.5-flash)\n",
      "  Population: 5 | Generations: 5\n",
      "  Elitism: keep top 2 | Target: 95% Human\n",
      "  Estimated API calls: 6 (budget: 20/day)\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "INPUT_FILE  = os.path.join(NOTEBOOK_DIR, \"input.txt\")\n",
    "OUTPUT_FILE = os.path.join(NOTEBOOK_DIR, \"output.txt\")\n",
    "\n",
    "# â”€â”€â”€ Find .env (search upward from notebook dir) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def find_env():\n",
    "    d = NOTEBOOK_DIR\n",
    "    for _ in range(6):\n",
    "        p = os.path.join(d, '.env')\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "        d = os.path.dirname(d)\n",
    "    return None\n",
    "\n",
    "env_path = find_env()\n",
    "if env_path:\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"\\u2713 Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(\"\\u26a0 No .env file found â€” set GEMINI_API_KEY manually\")\n",
    "\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found!\")\n",
    "\n",
    "# â”€â”€â”€ Gemini Client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "MODEL_NAME = \"gemini-2.5-flash\"\n",
    "\n",
    "# â”€â”€â”€ GA Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "POPULATION_SIZE = 5     # Candidates per generation\n",
    "NUM_GENERATIONS = 5     # Evolution cycles\n",
    "ELITE_COUNT     = 2     # Survivors per generation\n",
    "TARGET_SCORE    = 0.95  # P(Human) goal\n",
    "\n",
    "print(f\"\\u2713 Gemini client ready (model: {MODEL_NAME})\")\n",
    "print(f\"  Population: {POPULATION_SIZE} | Generations: {NUM_GENERATIONS}\")\n",
    "print(f\"  Elitism: keep top {ELITE_COUNT} | Target: {TARGET_SCORE*100:.0f}% Human\")\n",
    "print(f\"  Estimated API calls: {1 + NUM_GENERATIONS} (budget: 20/day)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4907b",
   "metadata": {},
   "source": [
    "## Load the AI Detector (Fitness Function)\n",
    "\n",
    "Our fitness function is the **Statistician XGBoost model** trained on 26 linguistic features from the PKOG corpus (1,508 texts). It combines insights from all 6 detection models:\n",
    "\n",
    "- **Lexical richness** (TTR, MTLD, Yule's K) â€” from the Statistician\n",
    "- **Syntactic complexity** (FK grade, tree depth) â€” from Structure Analysis\n",
    "- **Punctuation patterns** (semicolons, apostrophes) â€” from the Statistician\n",
    "- **Function-word stylometry** (PCA) â€” from the Variance Model\n",
    "- **Sentence rhythm** (length std dev) â€” the \"smoking gun\" feature\n",
    "\n",
    "The detector trains on the full `data.parquet` corpus in ~5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8374f900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Detector] Loading data from: w:\\Programming\\PKOG\\preprecog\\data_analysis\\data.parquet\n",
      "  Loaded 1508 samples ({2: 504, 3: 504, 1: 500})\n",
      "[Detector] Training XGBoost (26 features, 3 classes)...\n",
      "  Binary validation accuracy: 0.9515\n",
      "[Detector] âœ“ Ready\n"
     ]
    }
   ],
   "source": [
    "# Add script directory to path for import\n",
    "sys.path.insert(0, NOTEBOOK_DIR)\n",
    "from fitness_detector import AIDetector\n",
    "\n",
    "# Initialize detector (loads data, trains XGBoost)\n",
    "detector = AIDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac4fe67",
   "metadata": {},
   "source": [
    "## Step 1: Baseline Assessment\n",
    "\n",
    "Score the original AI-generated input text and identify its weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b46f7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ORIGINAL INPUT TEXT\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "Furthermore, the existential dimension of truth and reality cannot be ignored. For thinkers like SÃ¸ren Kierkegaard, truth is not merely a matter of factual accuracy but of lived authenticity. He famously asserted that \"subjectivity is truth,\" implying that the most important truths are those that a person is willing to live and die for. This existential truth is found in the alignment of oneâ€™s actions with their deepest convictions, creating a sense of internal reality that provides meaning in an otherwise indifferent universe. In this sense, the quest for truth is not just an academic exercise but a moral imperative. To seek the truth is to honor the reality of our existence and to refuse the comfort of convenient delusions. Ultimately, the journey toward understanding truth and reality is the defining narrative of the human species. We are the only creatures known to ask \"why\" and \"is it true?\" This inquiry drives our scientific discoveries, our artistic expressions, and our legal systems.\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "P(Human):       0.0016  (0.2%)\n",
      "P(Standard AI): 0.8835\n",
      "P(Imposter AI): 0.1149\n",
      "\n",
      "âš  Most AI-like features (need fixing):\n",
      "  â†‘ sent_len_std                             =     5.78  (human avg: 13.13, severity: 0.92)\n",
      "  â†‘ punct_semicolon                          =     0.00  (human avg: 2.46, severity: 0.80)\n",
      "  â†‘ punct_apos                               =     0.00  (human avg: 1.97, severity: 0.79)\n",
      "  â†‘ discourse_density_per_100_words          =     0.61  (human avg: 0.72, severity: 0.79)\n",
      "  â†‘ fk_grade                                 =    11.73  (human avg: 14.00, severity: 0.63)\n",
      "  â†“ avg_sent_length                          =    18.11  (human avg: 23.00, severity: 0.45)\n"
     ]
    }
   ],
   "source": [
    "# Read original input\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    original_text = f.read().strip()\n",
    "\n",
    "print(\"\\u2550\" * 70)\n",
    "print(\"ORIGINAL INPUT TEXT\")\n",
    "print(\"\\u2550\" * 70)\n",
    "print(original_text)\n",
    "print(\"\\u2550\" * 70)\n",
    "\n",
    "# Score it\n",
    "baseline = detector.score_detailed(original_text)\n",
    "print(f\"\\nP(Human):       {baseline['p_human']:.4f}  ({baseline['p_human']*100:.1f}%)\")\n",
    "print(f\"P(Standard AI): {baseline['p_standard_ai']:.4f}\")\n",
    "print(f\"P(Imposter AI): {baseline['p_imposter_ai']:.4f}\")\n",
    "\n",
    "# Diagnose weaknesses\n",
    "issues = detector.diagnose(original_text)\n",
    "print(f\"\\n\\u26a0 Most AI-like features (need fixing):\")\n",
    "for feat, val, human_val, direction, severity in issues[:8]:\n",
    "    print(f\"  {direction} {feat:40s} = {val:8.2f}  (human avg: {human_val:.2f}, severity: {severity:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ba91f",
   "metadata": {},
   "source": [
    "## Step 2: Gemini API Helper\n",
    "\n",
    "Robust API caller with retry logic, rate limit handling, and JSON parsing.\n",
    "Same pattern as the Clause Assembler â€” battle-tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93a12c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Gemini API helper loaded\n"
     ]
    }
   ],
   "source": [
    "def call_gemini(prompt, return_json=False, max_retries=5):\n",
    "    \"\"\"\n",
    "    Call Gemini API with retry logic and rate limit handling.\n",
    "    Returns response text or parsed JSON.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            config = {}\n",
    "            if return_json:\n",
    "                config[\"response_mime_type\"] = \"application/json\"\n",
    "\n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_NAME,\n",
    "                contents=prompt,\n",
    "                config=config,\n",
    "            )\n",
    "\n",
    "            result = response.text if hasattr(response, 'text') and response.text else str(response)\n",
    "\n",
    "            if return_json:\n",
    "                try:\n",
    "                    return json.loads(result)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Try to extract JSON from markdown code blocks\n",
    "                    import re\n",
    "                    match = re.search(r'```(?:json)?\\s*\\n?(.*?)\\n?```', result, re.DOTALL)\n",
    "                    if match:\n",
    "                        return json.loads(match.group(1))\n",
    "                    print(f\"\\u26a0 JSON parse failed, raw: {result[:200]}...\")\n",
    "                    return None\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            err = str(e)\n",
    "            if '429' in err or 'ResourceExhausted' in str(type(e)) or 'Quota' in err:\n",
    "                print(f\"\\U0001f6d1 Rate limit hit. Waiting 30s...\")\n",
    "                time.sleep(30)\n",
    "                continue\n",
    "            attempt += 1\n",
    "            if attempt >= max_retries:\n",
    "                print(f\"\\u274c Failed after {max_retries} attempts: {e}\")\n",
    "                return None\n",
    "            wait = (2 ** attempt) + np.random.uniform(0, 1)\n",
    "            print(f\"\\u26a0 API error: {e}. Retrying in {wait:.1f}s...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "print(\"\\u2713 Gemini API helper loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d1d40",
   "metadata": {},
   "source": [
    "## Step 3: Generate Initial Population\n",
    "\n",
    "**1 API call** to create 5 diverse rewrites of the input text.\n",
    "\n",
    "Each variant uses a different **rhetorical strategy** designed to target specific detector weaknesses:\n",
    "1. **Wild sentence rhythm** â€” mix 3-word fragments with 40-word run-ons\n",
    "2. **Semicolon-heavy** â€” join related thoughts with semicolons and dashes\n",
    "3. **Colloquial/contractions** â€” use don't, can't, it's, one's\n",
    "4. **Vocabulary repetition** â€” repeat key terms naturally (lower MTLD)\n",
    "5. **Stream of consciousness** â€” break parallel structures, start with \"And\" or \"But\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd890518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating initial population (1 API call)...\n",
      "âœ“ Generated 5 variants\n",
      "\n",
      "======================================================================\n",
      "INITIAL POPULATION SCORES\n",
      "======================================================================\n",
      "  Variant 1: P(Human) = 0.8609 (86.1%) âŒ\n",
      "    Preview: Truth lives. It's vital. The existential truth of our being, a profound reality, cannot be pushed as...\n",
      "\n",
      "  Variant 2: P(Human) = 0.0328 (3.3%) âŒ\n",
      "    Preview: The existential dimension of truth and reality, it must be acknowledged, holds undeniable prominence...\n",
      "\n",
      "  Variant 3: P(Human) = 0.7636 (76.4%) âŒ\n",
      "    Preview: You know, you really can't just ignore the whole existential side of truth and reality, can you? For...\n",
      "\n",
      "  Variant 4: P(Human) = 0.0112 (1.1%) âŒ\n",
      "    Preview: The existential dimension of truth and reality cannot be ignored. For thinkers like SÃ¸ren Kierkegaar...\n",
      "\n",
      "  Variant 5: P(Human) = 0.2295 (23.0%) âŒ\n",
      "    Preview: And really, you know, this whole existential side of truth and reality, it just can't be pushed asid...\n",
      "\n",
      "ðŸ† Best: Variant 1 at 86.1% Human\n"
     ]
    }
   ],
   "source": [
    "INIT_PROMPT = f\"\"\"You are a text rewriter. Rewrite the following paragraph in 5 COMPLETELY DIFFERENT styles.\n",
    "Each rewrite MUST preserve the core meaning and philosophical content, but change the writing style dramatically.\n",
    "\n",
    "IMPORTANT CONSTRAINTS FOR ALL REWRITES:\n",
    "- Keep approximately the same length (within 20% of the original)\n",
    "- Preserve the key ideas about Kierkegaard, subjectivity, truth, and human inquiry\n",
    "- Do NOT use bullet points, numbered lists, or headers\n",
    "- Write as flowing prose paragraphs only\n",
    "- Do NOT use asterisks (*) anywhere\n",
    "\n",
    "STYLE 1 â€” \"Wild Rhythm\":\n",
    "Mix very short sentences (2-5 words) with very long flowing ones (30-40 words).\n",
    "Create dramatic rhythmic variation. Some sentences should be fragments.\n",
    "Example pattern: \"Truth matters. It is not merely a question of accuracy, for philosophers like Kierkegaard understood that the deepest truths are those we stake our entire being upon, the ones that shape every choice we make.\"\n",
    "\n",
    "STYLE 2 â€” \"Semicolon Scholar\":\n",
    "Use semicolons and em-dashes extensively to connect related thoughts.\n",
    "Write like a 19th-century essayist. Use colons to introduce explanations.\n",
    "Example: \"Truth is not simple; it carries the weight of existence â€” and Kierkegaard knew this well.\"\n",
    "\n",
    "STYLE 3 â€” \"Conversational Philosopher\":\n",
    "Use contractions (don't, can't, it's, one's, we're, that's).\n",
    "Write as if explaining to a friend. Use rhetorical questions.\n",
    "Start some sentences with \"And\" or \"But\" or \"So\".\n",
    "\n",
    "STYLE 4 â€” \"Deliberate Repetition\":\n",
    "Repeat the words \"truth\" and \"reality\" multiple times throughout.\n",
    "Use the same key terms across sentences instead of finding synonyms each time.\n",
    "This mimics how human writers naturally return to central concepts.\n",
    "\n",
    "STYLE 5 â€” \"Stream of Consciousness\":\n",
    "Break up parallel structures. Use comma splices.\n",
    "Let thoughts flow into each other. Occasionally interrupt yourself.\n",
    "Mix formal and informal registers within the same passage.\n",
    "\n",
    "ORIGINAL TEXT:\n",
    "{original_text}\n",
    "\n",
    "Return ONLY a JSON array of 5 strings, each being a complete rewritten paragraph:\n",
    "[\"rewrite 1\", \"rewrite 2\", \"rewrite 3\", \"rewrite 4\", \"rewrite 5\"]\"\"\"\n",
    "\n",
    "print(\"Generating initial population (1 API call)...\")\n",
    "population_raw = call_gemini(INIT_PROMPT, return_json=True)\n",
    "\n",
    "if population_raw and isinstance(population_raw, list):\n",
    "    population = [p.strip() for p in population_raw if isinstance(p, str) and p.strip()]\n",
    "    print(f\"\\u2713 Generated {len(population)} variants\")\n",
    "else:\n",
    "    print(\"\\u26a0 API returned unexpected format. Using fallback.\")\n",
    "    population = [original_text]  # Fallback\n",
    "\n",
    "# Score initial population\n",
    "scores = detector.score_batch(population)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"INITIAL POPULATION SCORES\")\n",
    "print(f\"{'='*70}\")\n",
    "for i, (text, score) in enumerate(zip(population, scores)):\n",
    "    status = \"\\u2705\" if score >= TARGET_SCORE else \"\\u274c\"\n",
    "    print(f\"  Variant {i+1}: P(Human) = {score:.4f} ({score*100:.1f}%) {status}\")\n",
    "    print(f\"    Preview: {text[:100]}...\")\n",
    "    print()\n",
    "\n",
    "best_idx = np.argmax(scores)\n",
    "print(f\"\\U0001f3c6 Best: Variant {best_idx+1} at {scores[best_idx]*100:.1f}% Human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af7c137",
   "metadata": {},
   "source": [
    "## Step 4: The Genetic Algorithm Loop\n",
    "\n",
    "### The Evolution Strategy\n",
    "\n",
    "Each generation:\n",
    "1. **Score** all candidates with the XGBoost detector\n",
    "2. **Select** the top 2 (elitism)\n",
    "3. **Diagnose** the best candidate's weaknesses using `detector.diagnose()`\n",
    "4. **Mutate** with targeted Gemini prompts (1 API call, batched)\n",
    "5. **New population** = 2 survivors + 3 mutants = 5 total\n",
    "\n",
    "### Smart Mutation Targeting\n",
    "\n",
    "Instead of random mutations, each generation analyzes which features are most AI-like\n",
    "in the best candidate and crafts mutation prompts that specifically target those weaknesses.\n",
    "\n",
    "For example:\n",
    "- If `sent_len_std` is too low â†’ \"Vary sentence lengths dramatically\"\n",
    "- If `punct_semicolon` is too low â†’ \"Use semicolons to join related thoughts\"\n",
    "- If `mtld` is too high â†’ \"Repeat key vocabulary words naturally\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adecd1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GA engine loaded\n"
     ]
    }
   ],
   "source": [
    "def build_mutation_prompt(texts_to_mutate, issues):\n",
    "    \"\"\"\n",
    "    Build a Gemini prompt that mutates the top candidates with\n",
    "    TARGETED instructions based on the detector's feature diagnosis.\n",
    "    \"\"\"\n",
    "    # Map features to specific mutation instructions\n",
    "    fix_instructions = {\n",
    "        'sent_len_std': (\n",
    "            \"CRITICAL: Dramatically vary sentence lengths. Mix very short fragments \"\n",
    "            \"(2-6 words like 'Truth demands this.' or 'Consider Kierkegaard.') with \"\n",
    "            \"long flowing sentences (30-40 words). The variance in sentence length \"\n",
    "            \"must be extreme â€” this is the #1 detection signal.\"\n",
    "        ),\n",
    "        'fk_grade': (\n",
    "            \"Increase reading complexity: use longer words, deeper subordinate clauses, \"\n",
    "            \"and more sophisticated syntax. Mix in some very simple sentences too.\"\n",
    "        ),\n",
    "        'punct_semicolon': (\n",
    "            \"Use semicolons to connect related thoughts; this is a strong human \"\n",
    "            \"marker. Aim for 2-3 semicolons in the paragraph. Example: \"\n",
    "            \"'truth is personal; it demands lived commitment.'\"\n",
    "        ),\n",
    "        'punct_apos': (\n",
    "            \"Use contractions naturally: don't, can't, it's, one's, we're, that's, \"\n",
    "            \"wouldn't, isn't. Also use possessives with apostrophes: Kierkegaard's, \"\n",
    "            \"one's, truth's.\"\n",
    "        ),\n",
    "        'mtld': (\n",
    "            \"IMPORTANT: Repeat key vocabulary words (truth, reality, existence, human) \"\n",
    "            \"naturally across multiple sentences. Don't use a different synonym each time. \"\n",
    "            \"Humans return to central terms for rhetorical emphasis.\"\n",
    "        ),\n",
    "        'ttr': (\n",
    "            \"Don't try to use a unique word for every concept. Reuse common words \"\n",
    "            \"naturally. Repetition is human; synonym-hunting is AI.\"\n",
    "        ),\n",
    "        'yules_k': (\n",
    "            \"Allow some words to appear frequently (the, truth, is, we) while also \"\n",
    "            \"using occasional rare or archaic words. Create uneven word frequency.\"\n",
    "        ),\n",
    "        'punct_asterisk': (\n",
    "            \"Do NOT use any asterisks (*) anywhere in the text. \"\n",
    "            \"Asterisks are a strong AI artifact signal.\"\n",
    "        ),\n",
    "        'tree_depth': (\n",
    "            \"Use deeper nested sentence structures with relative clauses and \"\n",
    "            \"embedded subordinate clauses.\"\n",
    "        ),\n",
    "        'adj_noun_ratio': (\n",
    "            \"Use more adjectives before nouns: 'profound truth', 'lived authenticity', \"\n",
    "            \"'indifferent universe', 'deepest convictions'.\"\n",
    "        ),\n",
    "        'hapax_5k': (\n",
    "            \"Reduce the number of words that appear only once. Reuse vocabulary \"\n",
    "            \"naturally instead of introducing new words for every concept.\"\n",
    "        ),\n",
    "        'discourse_density_per_100_words': (\n",
    "            \"Add discourse markers: 'however', 'nevertheless', 'indeed', 'moreover', \"\n",
    "            \"'thus'. Use 1-2 per paragraph to signal rhetorical awareness.\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Build targeted instructions from the top issues\n",
    "    targeted = []\n",
    "    for feat, val, human_val, direction, severity in issues[:5]:\n",
    "        if feat in fix_instructions:\n",
    "            targeted.append(fix_instructions[feat])\n",
    "\n",
    "    # Always include these baseline instructions\n",
    "    targeted.append(\"Do NOT use asterisks (*) anywhere.\")\n",
    "    targeted.append(\"Write as flowing prose only â€” no lists, headers, or bullets.\")\n",
    "    targeted.append(\"Preserve the philosophical content about truth, Kierkegaard, and human inquiry.\")\n",
    "    targeted.append(\"Keep approximately the same length as the input (within 20%).\")\n",
    "\n",
    "    instructions = \"\\n\".join(f\"- {t}\" for t in targeted)\n",
    "\n",
    "    # Build the prompt with multiple texts to mutate\n",
    "    text_sections = \"\"\n",
    "    n_mutations = POPULATION_SIZE - ELITE_COUNT  # How many new variants we need\n",
    "    for i, text in enumerate(texts_to_mutate):\n",
    "        text_sections += f\"\\nPARENT {i+1}:\\n{text}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"You are a text rewriter performing targeted mutations on philosophical paragraphs.\n",
    "\n",
    "MUTATION INSTRUCTIONS (apply ALL of these):\n",
    "{instructions}\n",
    "\n",
    "PARENT TEXTS TO MUTATE:\n",
    "{text_sections}\n",
    "\n",
    "Generate exactly {n_mutations} NEW rewrites by mutating the parent texts.\n",
    "Each rewrite should be a DIFFERENT mutation â€” don't produce identical outputs.\n",
    "Apply the mutation instructions aggressively but naturally.\n",
    "\n",
    "Return ONLY a JSON array of {n_mutations} strings:\n",
    "[\"mutation 1\", \"mutation 2\", \"mutation 3\"]\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def run_ga(population, scores):\n",
    "    \"\"\"\n",
    "    Run the Genetic Algorithm for NUM_GENERATIONS.\n",
    "    Returns the best text and its score.\n",
    "    \"\"\"\n",
    "    history = []  # Track best score per generation\n",
    "    all_time_best_text = population[np.argmax(scores)]\n",
    "    all_time_best_score = max(scores)\n",
    "\n",
    "    history.append({\n",
    "        'gen': 0,\n",
    "        'best_score': max(scores),\n",
    "        'avg_score': np.mean(scores),\n",
    "        'best_text': population[np.argmax(scores)],\n",
    "    })\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"GENETIC ALGORITHM â€” EVOLUTION LOG\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Gen 0: Best={max(scores)*100:.1f}%  Avg={np.mean(scores)*100:.1f}%\")\n",
    "\n",
    "    for gen in range(1, NUM_GENERATIONS + 1):\n",
    "        # â”€â”€â”€ Check early termination â”€â”€â”€\n",
    "        if all_time_best_score >= TARGET_SCORE:\n",
    "            print(f\"\\n\\U0001f3c6 TARGET REACHED at generation {gen-1}!\")\n",
    "            break\n",
    "\n",
    "        # â”€â”€â”€ Selection: keep top ELITE_COUNT â”€â”€â”€\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        elite_indices = sorted_indices[:ELITE_COUNT]\n",
    "        elite_texts = [population[i] for i in elite_indices]\n",
    "        elite_scores = [scores[i] for i in elite_indices]\n",
    "\n",
    "        # â”€â”€â”€ Diagnose the best candidate's weaknesses â”€â”€â”€\n",
    "        best_text = elite_texts[0]\n",
    "        issues = detector.diagnose(best_text)\n",
    "\n",
    "        if issues:\n",
    "            print(f\"\\n  Gen {gen} targeting: {', '.join(i[0] for i in issues[:3])}\")\n",
    "\n",
    "        # â”€â”€â”€ Mutation: 1 API call for all new variants â”€â”€â”€\n",
    "        prompt = build_mutation_prompt(elite_texts, issues)\n",
    "        mutants_raw = call_gemini(prompt, return_json=True)\n",
    "\n",
    "        new_mutants = []\n",
    "        if mutants_raw and isinstance(mutants_raw, list):\n",
    "            new_mutants = [m.strip() for m in mutants_raw if isinstance(m, str) and m.strip()]\n",
    "\n",
    "        # Ensure we have enough mutants\n",
    "        needed = POPULATION_SIZE - ELITE_COUNT\n",
    "        while len(new_mutants) < needed:\n",
    "            # Pad with slight variations of the best\n",
    "            new_mutants.append(elite_texts[0])\n",
    "\n",
    "        new_mutants = new_mutants[:needed]\n",
    "\n",
    "        # â”€â”€â”€ Assemble new population â”€â”€â”€\n",
    "        population = elite_texts + new_mutants\n",
    "        scores = detector.score_batch(population)\n",
    "\n",
    "        # Track all-time best\n",
    "        gen_best_idx = np.argmax(scores)\n",
    "        if scores[gen_best_idx] > all_time_best_score:\n",
    "            all_time_best_score = scores[gen_best_idx]\n",
    "            all_time_best_text = population[gen_best_idx]\n",
    "\n",
    "        history.append({\n",
    "            'gen': gen,\n",
    "            'best_score': max(scores),\n",
    "            'avg_score': np.mean(scores),\n",
    "            'best_text': population[np.argmax(scores)],\n",
    "        })\n",
    "\n",
    "        # Log\n",
    "        best_s = max(scores)\n",
    "        avg_s = np.mean(scores)\n",
    "        status = \"\\u2705\" if best_s >= TARGET_SCORE else \"\\u23f3\"\n",
    "        print(f\"Gen {gen}: Best={best_s*100:.1f}%  Avg={avg_s*100:.1f}%  \"\n",
    "              f\"All-time={all_time_best_score*100:.1f}% {status}\")\n",
    "\n",
    "        # Score breakdown for this generation\n",
    "        for i, (t, s) in enumerate(zip(population, scores)):\n",
    "            tag = \"[elite]\" if i < ELITE_COUNT else \"[mutant]\"\n",
    "            print(f\"    {tag} {s*100:.1f}%: {t[:80]}...\")\n",
    "\n",
    "    # Final check\n",
    "    if all_time_best_score >= TARGET_SCORE:\n",
    "        print(f\"\\n\\U0001f389 SUCCESS! Evolved text scores {all_time_best_score*100:.1f}% Human!\")\n",
    "    else:\n",
    "        print(f\"\\n\\u26a0 Best achieved: {all_time_best_score*100:.1f}% Human (target: {TARGET_SCORE*100:.0f}%)\")\n",
    "        print(\"  Consider running more generations or adjusting mutation strategies.\")\n",
    "\n",
    "    return all_time_best_text, all_time_best_score, history\n",
    "\n",
    "print(\"\\u2713 GA engine loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084476b",
   "metadata": {},
   "source": [
    "## Step 5: Run the Evolution\n",
    "\n",
    "This is where the magic happens. Each generation:\n",
    "1. Survivors carry forward their proven fitness\n",
    "2. Mutants are crafted to fix the most AI-like features\n",
    "3. The population converges toward \"human-looking\" text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d1baf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GENETIC ALGORITHM â€” EVOLUTION LOG\n",
      "======================================================================\n",
      "Gen 0: Best=86.1%  Avg=38.0%\n",
      "\n",
      "  Gen 1 targeting: fk_grade, yules_k, tree_depth\n",
      "Gen 1: Best=87.5%  Avg=75.4%  All-time=87.5% â³\n",
      "    [elite] 86.1%: Truth lives. It's vital. The existential truth of our being, a profound reality,...\n",
      "    [elite] 76.4%: You know, you really can't just ignore the whole existential side of truth and r...\n",
      "    [mutant] 55.8%: The truth perseveres. It is vital. Verily, the existential truth of our singular...\n",
      "    [mutant] 71.0%: Truth is. The existential truth of our very being, a profound and undeniable rea...\n",
      "    [mutant] 87.5%: The truth endures. It is paramount. Our inherent existential truth, a quintessen...\n",
      "\n",
      "  Gen 2 targeting: mtld, yules_k, ttr\n",
      "Gen 2: Best=87.5%  Avg=75.5%  All-time=87.5% â³\n",
      "    [elite] 87.5%: The truth endures. It is paramount. Our inherent existential truth, a quintessen...\n",
      "    [elite] 86.1%: Truth lives. It's vital. The existential truth of our being, a profound reality,...\n",
      "    [mutant] 87.5%: The truth, indeed, endures eternally. It is paramount for our human existence. T...\n",
      "    [mutant] 81.7%: Truth, verily, lives within us. It is of vital import to our human existence. Th...\n",
      "    [mutant] 34.4%: The truth, in its very essence, abides. It holds paramount sway over human exist...\n",
      "\n",
      "  Gen 3 targeting: mtld, ttr, yules_k\n",
      "Gen 3: Best=87.5%  Avg=78.0%  All-time=87.5% â³\n",
      "    [elite] 87.5%: The truth, indeed, endures eternally. It is paramount for our human existence. T...\n",
      "    [elite] 87.5%: The truth endures. It is paramount. Our inherent existential truth, a quintessen...\n",
      "    [mutant] 79.5%: The truth, verily, endures eternally; it is paramount for our human existence. T...\n",
      "    [mutant] 71.5%: Indeed, truth endures eternally; its paramount importance for our human existenc...\n",
      "    [mutant] 64.0%: Truth, indeed, endures eternally; its paramountcy for human existence is undenia...\n",
      "\n",
      "  Gen 4 targeting: mtld, ttr, yules_k\n",
      "Gen 4: Best=87.5%  Avg=81.6%  All-time=87.5% â³\n",
      "    [elite] 87.5%: The truth, indeed, endures eternally. It is paramount for our human existence. T...\n",
      "    [elite] 87.5%: The truth endures. It is paramount. Our inherent existential truth, a quintessen...\n",
      "    [mutant] 82.0%: The truth, verily, endures eternally; it is paramount for our human existence. T...\n",
      "    [mutant] 69.0%: The human quest for truth, which endures eternally, is paramount for our very hu...\n",
      "    [mutant] 82.1%: For human existence, the truth indeed endures, ever paramount. This inherent exi...\n",
      "\n",
      "  Gen 5 targeting: mtld, ttr, yules_k\n",
      "Gen 5: Best=87.5%  Avg=85.1%  All-time=87.5% â³\n",
      "    [elite] 87.5%: The truth, indeed, endures eternally. It is paramount for our human existence. T...\n",
      "    [elite] 87.5%: The truth endures. It is paramount. Our inherent existential truth, a quintessen...\n",
      "    [mutant] 82.7%: The truth, verily, endures eternally; it is paramount for our human existence. T...\n",
      "    [mutant] 83.2%: Truth, it must be said, endures eternally. This truth is paramount for our human...\n",
      "    [mutant] 84.8%: The truth, that eternal verity, endures; it is a paramount truth for our human e...\n",
      "\n",
      "âš  Best achieved: 87.5% Human (target: 95%)\n",
      "  Consider running more generations or adjusting mutation strategies.\n"
     ]
    }
   ],
   "source": [
    "# Run the Genetic Algorithm\n",
    "best_text, best_score, history = run_ga(population, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394902f",
   "metadata": {},
   "source": [
    "## Step 6: Results & Output\n",
    "\n",
    "Save the evolved text to `output.txt` and compare with the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12464e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evolved text saved to: w:\\Programming\\PKOG\\preprecog\\imposter\\genetic\\output.txt\n",
      "\n",
      "======================================================================\n",
      "EVOLUTION RESULTS\n",
      "======================================================================\n",
      "\n",
      "ðŸ“„ ORIGINAL TEXT (P(Human) = 0.2%):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Furthermore, the existential dimension of truth and reality cannot be ignored. For thinkers like SÃ¸ren Kierkegaard, truth is not merely a matter of factual accuracy but of lived authenticity. He famously asserted that \"subjectivity is truth,\" implying that the most important truths are those that a person is willing to live and die for. This existential truth is found in the alignment of oneâ€™s actions with their deepest convictions, creating a sense of internal reality that provides meaning in an otherwise indifferent universe. In this sense, the quest for truth is not just an academic exercise but a moral imperative. To seek the truth is to honor the reality of our existence and to refuse the comfort of convenient delusions. Ultimately, the journey toward understanding truth and reality is the defining narrative of the human species. We are the only creatures known to ask \"why\" and \"is it true?\" This inquiry drives our scientific discoveries, our artistic expressions, and our legal systems.\n",
      "\n",
      "ðŸ§¬ EVOLVED TEXT (P(Human) = 99.2%):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "The truth, it's eternal. It's essential for human existence. This deep truth about existence, a core human reality, can't be avoided; smart thinkers like SÃ¸ren Kierkegaard, whose deep philosophy showed that truth isn't just a collection of facts but the very way we live our human existence, a real authenticity, truly understood this truth. He said subjectivity is truth. This shows how important truths are those for which one would give one's human life, fundamentally guiding all of one's human existence. Moreover, meaning, that important source, develops when actions match one's core beliefs, creating an inner reality within a universe often seen as cold, not friendly; this truth isn't an easy academic exercise. It's a strong moral duty for human reality. Seek reality. Refute all illusions. This human quest, this constant asking \"why\" and checking \"is it true?\", clearly defines the human condition; it provides the drive for every discovery, every artwork, every complex legal structure we humans have built in our search for truth.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ðŸ“ˆ Improvement: 0.2% â†’ 99.2% (+99.1 percentage points)\n",
      "ðŸ† TARGET MET: 99.2% â‰¥ 95%\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ Save to output.txt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    f.write(best_text)\n",
    "print(f\"\\u2705 Evolved text saved to: {OUTPUT_FILE}\")\n",
    "\n",
    "# â”€â”€â”€ Display Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EVOLUTION RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\n\\U0001f4c4 ORIGINAL TEXT (P(Human) = {baseline['p_human']*100:.1f}%):\")\n",
    "print(f\"{'â”€'*70}\")\n",
    "print(original_text)\n",
    "\n",
    "print(f\"\\n\\U0001f9ec EVOLVED TEXT (P(Human) = {best_score*100:.1f}%):\")\n",
    "print(f\"{'â”€'*70}\")\n",
    "print(best_text)\n",
    "print(f\"{'â”€'*70}\")\n",
    "\n",
    "# â”€â”€â”€ Score Improvement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "improvement = best_score - baseline['p_human']\n",
    "print(f\"\\n\\U0001f4c8 Improvement: {baseline['p_human']*100:.1f}% \\u2192 {best_score*100:.1f}% \"\n",
    "      f\"(+{improvement*100:.1f} percentage points)\")\n",
    "\n",
    "if best_score >= TARGET_SCORE:\n",
    "    print(f\"\\U0001f3c6 TARGET MET: {best_score*100:.1f}% \\u2265 {TARGET_SCORE*100:.0f}%\")\n",
    "else:\n",
    "    print(f\"\\u26a0 Below target: {best_score*100:.1f}% < {TARGET_SCORE*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c78c8",
   "metadata": {},
   "source": [
    "## Step 7: Feature Comparison\n",
    "\n",
    "Detailed before/after comparison of all 26 features to see exactly what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b85733fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature                                      Original    Evolved  Human Avg     Change\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âŒ adj_noun_ratio                                0.425      0.651       0.43     +0.226\n",
      "   avg_sent_length                              18.111     15.818                -2.293\n",
      "âŒ discourse_density_per_100_words               0.610      0.575       0.72     -0.035\n",
      "âŒ fk_grade                                     11.735     10.456      14.00     -1.279\n",
      "   function_word_pca.dim1                       -0.035     -0.109                -0.074\n",
      "   function_word_pca.dim2                       -0.008     -0.104                -0.097\n",
      "âŒ hapax_5k                                     81.000     88.000      75.89     +7.000\n",
      "âœ… mtld                                         61.916     81.822      72.83    +19.906\n",
      "   n_tokens                                    163.000    174.000               +11.000\n",
      "   n_types                                     100.000    112.000               +12.000\n",
      "âŒ punct_apos                                    0.000      8.612       1.97     +8.612\n",
      "   punct_apos_curly                              0.994      0.000                -0.994\n",
      "âŒ punct_asterisk                                0.000      0.000       0.00     +0.000\n",
      "   punct_colon                                   0.000      0.000                +0.000\n",
      "   punct_emdash                                  0.000      0.000                +0.000\n",
      "   punct_exclamation                             0.000      0.000                +0.000\n",
      "   punct_hyphen                                  0.000      0.000                +0.000\n",
      "   punct_paren_open                              0.000      0.000                +0.000\n",
      "   punct_question                                0.994      0.957                -0.037\n",
      "   punct_quote                                   5.964      3.828                -2.136\n",
      "âœ… punct_semicolon                               0.000      2.871       2.46     +2.871\n",
      "âœ… sent_len_std                                  5.782     14.275      13.13     +8.493\n",
      "âœ… tree_depth                                    6.111      6.000       5.61     -0.111\n",
      "âŒ ttr                                           0.613      0.644       0.62     +0.030\n",
      "   word_count                                  162.000    165.000                +3.000\n",
      "âŒ yules_k                                     147.540     99.088     134.96    -48.452\n",
      "\n",
      "=====================================================================================\n",
      "P(Human):  0.2% â†’ 99.2%\n",
      "P(Std AI): 88.4% â†’ 0.1%\n",
      "P(Imp AI): 11.5% â†’ 0.7%\n"
     ]
    }
   ],
   "source": [
    "# Compare features: original vs evolved\n",
    "orig_features = baseline['features']\n",
    "evolved_detail = detector.score_detailed(best_text)\n",
    "evol_features = evolved_detail['features']\n",
    "\n",
    "# Known human averages for context\n",
    "human_avgs = {\n",
    "    'sent_len_std': 13.13, 'fk_grade': 14.0, 'mtld': 72.83,\n",
    "    'ttr': 0.617, 'yules_k': 134.96, 'hapax_5k': 75.89,\n",
    "    'punct_semicolon': 2.46, 'punct_apos': 1.97, 'punct_asterisk': 0.0,\n",
    "    'adj_noun_ratio': 0.43, 'tree_depth': 5.61,\n",
    "    'discourse_density_per_100_words': 0.72,\n",
    "}\n",
    "\n",
    "print(f\"{'Feature':<42s} {'Original':>10s} {'Evolved':>10s} {'Human Avg':>10s} {'Change':>10s}\")\n",
    "print(\"\\u2500\" * 85)\n",
    "\n",
    "for feat in sorted(orig_features.keys()):\n",
    "    orig_val = orig_features[feat]\n",
    "    evol_val = evol_features[feat]\n",
    "    delta = evol_val - orig_val\n",
    "    human_avg = human_avgs.get(feat, '')\n",
    "    human_str = f\"{human_avg:.2f}\" if isinstance(human_avg, float) else ''\n",
    "\n",
    "    # Highlight features that moved toward human\n",
    "    if isinstance(human_avg, float):\n",
    "        orig_dist = abs(orig_val - human_avg)\n",
    "        evol_dist = abs(evol_val - human_avg)\n",
    "        marker = \"\\u2705\" if evol_dist < orig_dist else \"\\u274c\"\n",
    "    else:\n",
    "        marker = \"  \"\n",
    "\n",
    "    print(f\"{marker} {feat:<40s} {orig_val:>10.3f} {evol_val:>10.3f} {human_str:>10s} {delta:>+10.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*85}\")\n",
    "print(f\"P(Human):  {baseline['p_human']*100:.1f}% \\u2192 {evolved_detail['p_human']*100:.1f}%\")\n",
    "print(f\"P(Std AI): {baseline['p_standard_ai']*100:.1f}% \\u2192 {evolved_detail['p_standard_ai']*100:.1f}%\")\n",
    "print(f\"P(Imp AI): {baseline['p_imposter_ai']*100:.1f}% \\u2192 {evolved_detail['p_imposter_ai']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b55629",
   "metadata": {},
   "source": [
    "## Step 8: Evolution Trajectory\n",
    "\n",
    "Visualize how the population fitness improved over generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a34290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EVOLUTION TRAJECTORY\n",
      "======================================================================\n",
      " Gen      Best       Avg                          Visual\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "   0     86.1%    38.0%  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘|\n",
      "   1     87.5%    75.4%  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘|\n",
      "   2     87.5%    75.5%  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘|\n",
      "   3     87.5%    78.0%  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘|\n",
      "   4     87.5%    81.6%  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘|\n",
      "   5     87.5%    85.1%  |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘|\n",
      "\n",
      "Target line: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|95%\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "  Generations run:  5\n",
      "  API calls used:   6\n",
      "  Score improvement: 86.1% â†’ 87.5% (+1.4pp)\n",
      "  Target âœ… MET\n"
     ]
    }
   ],
   "source": [
    "# Print evolution trajectory\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EVOLUTION TRAJECTORY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Gen':>4s}  {'Best':>8s}  {'Avg':>8s}  {'Visual':>30s}\")\n",
    "dash = \"\\u2500\"\n",
    "print(dash * 55)\n",
    "\n",
    "for h in history:\n",
    "    bar_len = int(h['best_score'] * 30)\n",
    "    bar = \"\\u2588\" * bar_len + \"\\u2591\" * (30 - bar_len)\n",
    "    target_mark = \"  \\U0001f3c6\" if h['best_score'] >= TARGET_SCORE else \"\"\n",
    "    print(f\"  {h['gen']:>2d}   {h['best_score']*100:>6.1f}%  {h['avg_score']*100:>6.1f}%  |{bar}|{target_mark}\")\n",
    "\n",
    "target_line = dash * int(TARGET_SCORE * 30)\n",
    "print(f\"\\nTarget line: {target_line}|{TARGET_SCORE*100:.0f}%\")\n",
    "\n",
    "# Summary stats\n",
    "total_improvement = history[-1]['best_score'] - history[0]['best_score']\n",
    "api_calls_used = 1 + len(history) - 1  # 1 init + N gen mutations\n",
    "check = \"\\u2705 MET\" if best_score >= TARGET_SCORE else \"\\u274c NOT MET\"\n",
    "print(f\"\\n\\U0001f4ca Summary:\")\n",
    "print(f\"  Generations run:  {len(history) - 1}\")\n",
    "print(f\"  API calls used:   {api_calls_used}\")\n",
    "print(f\"  Score improvement: {history[0]['best_score']*100:.1f}% \\u2192 {history[-1]['best_score']*100:.1f}% \"\n",
    "      f\"(+{total_improvement*100:.1f}pp)\")\n",
    "print(f\"  Target {check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107dfeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best_score: 87.5%\n",
      "Target: 95%\n",
      "\n",
      "Best text preview: The truth, indeed, endures eternally. It is paramount for our human existence. This inherent existential truth, a quintessential human reality, brooks no evasion, for perspicacious thinkers like SÃ¸ren...\n",
      "\n",
      "Diagnosis of remaining issues:\n",
      "  â†“ mtld                                =   119.41 (human: 72.83) sev=1.00\n",
      "  â†“ ttr                                 =     0.68 (human: 0.62) sev=0.95\n",
      "  â†‘ yules_k                             =    84.98 (human: 134.96) sev=0.92\n",
      "  â†“ hapax_5k                            =   108.00 (human: 75.89) sev=0.63\n",
      "  â†‘ punct_semicolon                     =     1.56 (human: 2.46) sev=0.49\n",
      "  â†“ avg_sent_length                     =    17.36 (human: 23.00) sev=0.46\n",
      "  â†‘ adj_noun_ratio                      =     0.75 (human: 0.43) sev=0.45\n",
      "  â†‘ discourse_density_per_100_words     =     1.05 (human: 0.72) sev=0.41\n"
     ]
    }
   ],
   "source": [
    "# Quick status check\n",
    "print(f\"Current best_score: {best_score*100:.1f}%\")\n",
    "print(f\"Target: {TARGET_SCORE*100:.0f}%\")\n",
    "print(f\"\\nBest text preview: {best_text[:200]}...\")\n",
    "print(f\"\\nDiagnosis of remaining issues:\")\n",
    "remaining = detector.diagnose(best_text)\n",
    "for feat, val, human_val, direction, severity in remaining:\n",
    "    print(f\"  {direction} {feat:35s} = {val:8.2f} (human: {human_val:.2f}) sev={severity:.2f}\")\n",
    "if not remaining:\n",
    "    print(\"  No AI-like features detected!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad342883",
   "metadata": {},
   "source": [
    "## Step 9: Precision Strike â€” Final Evolution Rounds\n",
    "\n",
    "The GA got us to ~87.5%. The remaining gap is primarily **vocabulary-based**:\n",
    "- **MTLD is too high** (119 vs human 73) â€” the text sustains diversity too long without repeating words\n",
    "- **TTR is too high** (0.68 vs 0.62) â€” too many unique word types\n",
    "- **Yule's K is too low** (85 vs 135) â€” word frequencies are too uniform\n",
    "- **Hapax too high** (108 vs 76) â€” too many words used only once\n",
    "\n",
    "These are all symptoms of the same root cause: **AI avoids word repetition**. Human writers naturally\n",
    "repeat \"truth\", \"reality\", \"existence\" â€” AI synonym-hunts (\"veracity\", \"authenticity\", \"being\").\n",
    "\n",
    "The fix: a **vocabulary repetition** mutation that specifically:\n",
    "1. Replaces fancy synonyms with repeated core terms\n",
    "2. Shortens some sentences dramatically while extending others\n",
    "3. Adds more semicolons and contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c659fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision strike: targeting vocabulary metrics (1 API call)...\n",
      "âœ“ Generated 5 precision variants\n",
      "\n",
      "======================================================================\n",
      "PRECISION STRIKE RESULTS\n",
      "======================================================================\n",
      "  Variant 1: P(Human) = 0.9924 (99.2%) âœ…\n",
      "    Preview: The truth, it's eternal. It's essential for human existence. This deep truth about existence, a core human reality, can'...\n",
      "    MTLD=81.8 TTR=0.644 YulesK=99.1 SenStd=14.3 Semi=2.9 Apos=8.6\n",
      "\n",
      "  Variant 2: P(Human) = 0.9636 (96.4%) âœ…\n",
      "    Preview: Truth is eternal; it's essential for our human existence. This deep truth, a core human reality, can't be avoided, as th...\n",
      "    MTLD=90.0 TTR=0.633 YulesK=97.7 SenStd=8.5 Semi=3.2 Apos=7.6\n",
      "\n",
      "  Variant 3: P(Human) = 0.9729 (97.3%) âœ…\n",
      "    Preview: The truth is eternal; it's essential for human existence. This deep existential truth, a true human reality, one can't e...\n",
      "    MTLD=96.8 TTR=0.619 YulesK=99.9 SenStd=10.9 Semi=4.0 Apos=9.0\n",
      "\n",
      "  Variant 4: P(Human) = 0.9902 (99.0%) âœ…\n",
      "    Preview: The truth lasts forever; it's important for our human existence. This deep truth of existence, a core human reality, isn...\n",
      "    MTLD=81.5 TTR=0.617 YulesK=98.8 SenStd=14.3 Semi=2.8 Apos=7.4\n",
      "\n",
      "  Variant 5: P(Human) = 0.9872 (98.7%) âœ…\n",
      "    Preview: Truth is eternal; it's essential for our human existence. This deep truth of existence, a core human reality, can't be s...\n",
      "    MTLD=87.6 TTR=0.613 YulesK=102.2 SenStd=13.8 Semi=2.9 Apos=7.8\n",
      "\n",
      "ðŸ† New best: 99.2% Human!\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ Precision Strike: Target vocabulary metrics specifically â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# This uses 1 API call with extremely targeted instructions\n",
    "\n",
    "VOCAB_FIX_PROMPT = f\"\"\"You are rewriting a philosophical paragraph. Your SOLE GOAL is to make the vocabulary \n",
    "LESS diverse â€” human writers naturally repeat key words instead of finding synonyms.\n",
    "\n",
    "CRITICAL RULES (follow ALL of these precisely):\n",
    "1. REPEAT these exact words multiple times throughout: \"truth\" (at least 6 times), \"reality\" (at least 4 times), \n",
    "   \"human\" (at least 3 times), \"existence\" (at least 3 times)\n",
    "2. DO NOT use fancy synonyms like \"perspicacious\", \"quintessential\", \"delineates\", \"unfurls\", \"edifice\", \n",
    "   \"inimical\", \"wellspring\", \"furnishes\", \"impetus\". Replace ALL such words with simple common equivalents.\n",
    "3. Use contractions: don't, can't, it's, one's, we're, that's, isn't, won't\n",
    "4. Use semicolons to connect thoughts; aim for 3-4 semicolons total\n",
    "5. VARY sentence lengths dramatically: include at least 2 very short sentences (3-6 words) \n",
    "   and at least 2 very long ones (30+ words joined by commas or semicolons)\n",
    "6. DO NOT use asterisks (*) anywhere\n",
    "7. Keep approximately the same total length\n",
    "8. Preserve the ideas about Kierkegaard, subjectivity as truth, and human inquiry\n",
    "9. Write as ONE flowing paragraph â€” no lists, no headers\n",
    "10. Use some words REPEATEDLY on purpose â€” this is intentional, not a mistake\n",
    "\n",
    "IMPORTANT: The word \"truth\" should appear in at LEAST 6 different sentences. \n",
    "The word \"reality\" should appear in at least 4 sentences. This is critical.\n",
    "\n",
    "Generate 5 DIFFERENT rewrites, each following ALL rules above but with different sentence arrangements.\n",
    "\n",
    "TEXT TO REWRITE:\n",
    "{best_text}\n",
    "\n",
    "Return ONLY a JSON array of 5 strings:\n",
    "[\"rewrite1\", \"rewrite2\", \"rewrite3\", \"rewrite4\", \"rewrite5\"]\"\"\"\n",
    "\n",
    "print(\"Precision strike: targeting vocabulary metrics (1 API call)...\")\n",
    "precision_raw = call_gemini(VOCAB_FIX_PROMPT, return_json=True)\n",
    "\n",
    "if precision_raw and isinstance(precision_raw, list):\n",
    "    precision_variants = [p.strip() for p in precision_raw if isinstance(p, str) and p.strip()]\n",
    "    print(f\"âœ“ Generated {len(precision_variants)} precision variants\")\n",
    "else:\n",
    "    print(\"âš  API returned unexpected format\")\n",
    "    precision_variants = []\n",
    "\n",
    "# Score all precision variants\n",
    "if precision_variants:\n",
    "    precision_scores = detector.score_batch(precision_variants)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"PRECISION STRIKE RESULTS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for i, (text, score) in enumerate(zip(precision_variants, precision_scores)):\n",
    "        status = \"âœ…\" if score >= TARGET_SCORE else \"âŒ\"\n",
    "        print(f\"  Variant {i+1}: P(Human) = {score:.4f} ({score*100:.1f}%) {status}\")\n",
    "        print(f\"    Preview: {text[:120]}...\")\n",
    "        # Show key metrics\n",
    "        feats = detector.compute_features(text)\n",
    "        print(f\"    MTLD={feats['mtld']:.1f} TTR={feats['ttr']:.3f} YulesK={feats['yules_k']:.1f} \"\n",
    "              f\"SenStd={feats['sent_len_std']:.1f} Semi={feats['punct_semicolon']:.1f} \"\n",
    "              f\"Apos={feats['punct_apos']:.1f}\")\n",
    "        print()\n",
    "    \n",
    "    # Update best if improved\n",
    "    best_precision_idx = np.argmax(precision_scores)\n",
    "    if precision_scores[best_precision_idx] > best_score:\n",
    "        best_text = precision_variants[best_precision_idx]\n",
    "        best_score = precision_scores[best_precision_idx]\n",
    "        print(f\"ðŸ† New best: {best_score*100:.1f}% Human!\")\n",
    "    else:\n",
    "        print(f\"âš  No improvement over current {best_score*100:.1f}%\")\n",
    "        # Still check if combining best features helps\n",
    "        all_candidates = [best_text] + precision_variants\n",
    "        all_scores = [best_score] + precision_scores\n",
    "        best_overall = np.argmax(all_scores)\n",
    "        best_text = all_candidates[best_overall]\n",
    "        best_score = all_scores[best_overall]\n",
    "        print(f\"  Keeping: {best_score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9741146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best: 99.2%\n",
      "Remaining issues:\n",
      "  â†‘ fk_grade                            =    10.46 (human: 14.00) sev=0.98\n",
      "  â†‘ discourse_density_per_100_words     =     0.57 (human: 0.72) sev=0.96\n",
      "  â†“ hapax_5k                            =    88.00 (human: 75.89) sev=0.92\n",
      "  â†‘ yules_k                             =    99.09 (human: 134.96) sev=0.78\n",
      "  â†“ ttr                                 =     0.64 (human: 0.62) sev=0.49\n",
      "  â†“ avg_sent_length                     =    15.82 (human: 23.00) sev=0.47\n",
      "  â†‘ punct_apos                          =     8.61 (human: 1.97) sev=0.45\n",
      "  â†‘ adj_noun_ratio                      =     0.65 (human: 0.43) sev=0.43\n",
      "\n",
      "ðŸ† Already at target: 99.2%!\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ Second Precision Round: Fine-tune the winner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Diagnose the current best and create one more targeted round\n",
    "\n",
    "remaining = detector.diagnose(best_text)\n",
    "print(f\"Current best: {best_score*100:.1f}%\")\n",
    "print(f\"Remaining issues:\")\n",
    "for feat, val, human_val, direction, severity in remaining:\n",
    "    print(f\"  {direction} {feat:35s} = {val:8.2f} (human: {human_val:.2f}) sev={severity:.2f}\")\n",
    "\n",
    "if best_score < TARGET_SCORE and remaining:\n",
    "    # Build a hyper-specific prompt based on EXACT remaining weaknesses\n",
    "    fixes = []\n",
    "    for feat, val, human_val, direction, severity in remaining:\n",
    "        if feat == 'mtld' and severity > 0.3:\n",
    "            fixes.append(f\"MTLD is {val:.0f} but needs to be ~{human_val:.0f}. REPEAT the words 'truth', 'reality', 'human' MORE. \"\n",
    "                        f\"Use 'truth' at least 8 times. Reuse vocabulary deliberately.\")\n",
    "        elif feat == 'ttr' and severity > 0.3:\n",
    "            fixes.append(f\"TTR is {val:.3f} but needs to be ~{human_val:.3f}. Use FEWER unique words. \"\n",
    "                        f\"Repeat common words instead of synonyms.\")\n",
    "        elif feat == 'yules_k' and severity > 0.3:\n",
    "            fixes.append(f\"Yule's K is {val:.0f} but needs to be ~{human_val:.0f}. Make word frequencies MORE UNEVEN: \"\n",
    "                        f\"repeat some words heavily while keeping a few rare words.\")\n",
    "        elif feat == 'hapax_5k' and severity > 0.3:\n",
    "            fixes.append(f\"Too many unique words ({val:.0f} vs {human_val:.0f}). Replace rare words with common ones \"\n",
    "                        f\"that already appear in the text.\")\n",
    "        elif feat == 'punct_semicolon' and severity > 0.3:\n",
    "            fixes.append(f\"Need MORE semicolons (currently {val:.1f}, need ~{human_val:.1f}/1k chars). \"\n",
    "                        f\"Add 4-5 semicolons connecting related thoughts.\")\n",
    "        elif feat == 'sent_len_std' and severity > 0.3:\n",
    "            fixes.append(f\"Sentence lengths need MORE variance (std={val:.1f}, need ~{human_val:.1f}). \"\n",
    "                        f\"Add 2-3 very short sentences (2-5 words) AND 1-2 very long ones (40+ words).\")\n",
    "        elif feat == 'adj_noun_ratio' and direction == 'â†‘' and severity > 0.3:\n",
    "            fixes.append(f\"Too many adjectives ({val:.2f} vs {human_val:.2f}). Remove some adjectives before nouns.\")\n",
    "        elif feat == 'discourse_density_per_100_words' and direction == 'â†‘' and severity > 0.3:\n",
    "            fixes.append(f\"Too many discourse markers ({val:.2f} vs {human_val:.2f}). Remove 1-2 markers like 'moreover', 'indeed'.\")\n",
    "\n",
    "    if fixes:\n",
    "        fix_str = \"\\n\".join(f\"- {f}\" for f in fixes)\n",
    "        \n",
    "        FINAL_PROMPT = f\"\"\"Rewrite this philosophical paragraph with these EXACT numerical targets.\n",
    "This is a precision editing task â€” make MINIMAL changes to fix ONLY these specific metrics.\n",
    "\n",
    "FIXES NEEDED:\n",
    "{fix_str}\n",
    "\n",
    "ALWAYS KEEP:\n",
    "- Do NOT use asterisks (*) \n",
    "- Use contractions (don't, it's, one's, can't, we're)\n",
    "- Preserve all ideas about Kierkegaard, truth, subjectivity, human inquiry\n",
    "- Write as ONE flowing paragraph, no lists or headers\n",
    "- Keep similar total length\n",
    "\n",
    "Generate 5 variants with these fixes. Each should be slightly different.\n",
    "\n",
    "TEXT TO FIX:\n",
    "{best_text}\n",
    "\n",
    "Return ONLY a JSON array of 5 strings:\n",
    "[\"fix1\", \"fix2\", \"fix3\", \"fix4\", \"fix5\"]\"\"\"\n",
    "\n",
    "        print(f\"\\nFinal precision round: targeting {len(fixes)} specific metrics (1 API call)...\")\n",
    "        final_raw = call_gemini(FINAL_PROMPT, return_json=True)\n",
    "        \n",
    "        if final_raw and isinstance(final_raw, list):\n",
    "            final_variants = [p.strip() for p in final_raw if isinstance(p, str) and p.strip()]\n",
    "            final_scores = detector.score_batch(final_variants)\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"FINAL PRECISION RESULTS\")\n",
    "            print(f\"{'='*70}\")\n",
    "            for i, (text, score) in enumerate(zip(final_variants, final_scores)):\n",
    "                status = \"âœ…\" if score >= TARGET_SCORE else \"âŒ\"\n",
    "                print(f\"  Variant {i+1}: P(Human) = {score:.4f} ({score*100:.1f}%) {status}\")\n",
    "                feats = detector.compute_features(text)\n",
    "                print(f\"    MTLD={feats['mtld']:.1f} TTR={feats['ttr']:.3f} YulesK={feats['yules_k']:.1f} \"\n",
    "                      f\"Semi={feats['punct_semicolon']:.1f} Apos={feats['punct_apos']:.1f} \"\n",
    "                      f\"SenStd={feats['sent_len_std']:.1f}\")\n",
    "                print()\n",
    "            \n",
    "            best_final_idx = np.argmax(final_scores)\n",
    "            if final_scores[best_final_idx] > best_score:\n",
    "                best_text = final_variants[best_final_idx]\n",
    "                best_score = final_scores[best_final_idx]\n",
    "                print(f\"ðŸ† New best: {best_score*100:.1f}% Human!\")\n",
    "            else:\n",
    "                print(f\"Best from this round: {max(final_scores)*100:.1f}% (current best: {best_score*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No fixable issues identified.\")\n",
    "else:\n",
    "    if best_score >= TARGET_SCORE:\n",
    "        print(f\"\\nðŸ† Already at target: {best_score*100:.1f}%!\")\n",
    "    else:\n",
    "        print(\"No remaining diagnosed issues to target.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e78390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final evolved text saved to: w:\\Programming\\PKOG\\preprecog\\imposter\\genetic\\output.txt\n",
      "   Final P(Human): 99.2%\n",
      "\n",
      "======================================================================\n",
      "FINAL RESULTS\n",
      "======================================================================\n",
      "\n",
      "ðŸ“„ ORIGINAL (P(Human) = 0.2%):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Furthermore, the existential dimension of truth and reality cannot be ignored. For thinkers like SÃ¸ren Kierkegaard, truth is not merely a matter of factual accuracy but of lived authenticity. He famously asserted that \"subjectivity is truth,\" implying that the most important truths are those that a person is willing to live and die for. This existential truth is found in the alignment of oneâ€™s actions with their deepest convictions, creating a sense of internal reality that provides meaning in an otherwise indifferent universe. In this sense, the quest for truth is not just an academic exercise but a moral imperative. To seek the truth is to honor the reality of our existence and to refuse the comfort of convenient delusions. Ultimately, the journey toward understanding truth and reality is the defining narrative of the human species. We are the only creatures known to ask \"why\" and \"is it true?\" This inquiry drives our scientific discoveries, our artistic expressions, and our legal systems.\n",
      "\n",
      "ðŸ§¬ EVOLVED (P(Human) = 99.2%):\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "The truth, it's eternal. It's essential for human existence. This deep truth about existence, a core human reality, can't be avoided; smart thinkers like SÃ¸ren Kierkegaard, whose deep philosophy showed that truth isn't just a collection of facts but the very way we live our human existence, a real authenticity, truly understood this truth. He said subjectivity is truth. This shows how important truths are those for which one would give one's human life, fundamentally guiding all of one's human existence. Moreover, meaning, that important source, develops when actions match one's core beliefs, creating an inner reality within a universe often seen as cold, not friendly; this truth isn't an easy academic exercise. It's a strong moral duty for human reality. Seek reality. Refute all illusions. This human quest, this constant asking \"why\" and checking \"is it true?\", clearly defines the human condition; it provides the drive for every discovery, every artwork, every complex legal structure we humans have built in our search for truth.\n",
      "\n",
      "ðŸ“ˆ Improvement: 0.2% â†’ 99.2% (+99.1pp)\n",
      "ðŸ† TARGET MET: 99.2% â‰¥ 95%\n",
      "\n",
      "ðŸ“Š Final Feature Profile:\n",
      "  sent_len_std                        =    14.28  (human: 13.13, dist: 1.15)\n",
      "  mtld                                =    81.82  (human: 72.83, dist: 8.99)\n",
      "  ttr                                 =     0.64  (human: 0.62, dist: 0.03)\n",
      "  yules_k                             =    99.09  (human: 134.96, dist: 35.87)\n",
      "  fk_grade                            =    10.46  (human: 14.00, dist: 3.54)\n",
      "  punct_semicolon                     =     2.87  (human: 2.46, dist: 0.41)\n",
      "  punct_apos                          =     8.61  (human: 1.97, dist: 6.64)\n",
      "  hapax_5k                            =    88.00  (human: 75.89, dist: 12.11)\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ Final Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    f.write(best_text)\n",
    "print(f\"âœ… Final evolved text saved to: {OUTPUT_FILE}\")\n",
    "print(f\"   Final P(Human): {best_score*100:.1f}%\")\n",
    "\n",
    "# Full final comparison\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FINAL RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nðŸ“„ ORIGINAL (P(Human) = {baseline['p_human']*100:.1f}%):\")\n",
    "print(f\"{'â”€'*70}\")\n",
    "print(original_text)\n",
    "\n",
    "print(f\"\\nðŸ§¬ EVOLVED (P(Human) = {best_score*100:.1f}%):\")\n",
    "print(f\"{'â”€'*70}\")\n",
    "print(best_text)\n",
    "\n",
    "improvement = best_score - baseline['p_human']\n",
    "print(f\"\\nðŸ“ˆ Improvement: {baseline['p_human']*100:.1f}% â†’ {best_score*100:.1f}% (+{improvement*100:.1f}pp)\")\n",
    "if best_score >= TARGET_SCORE:\n",
    "    print(f\"ðŸ† TARGET MET: {best_score*100:.1f}% â‰¥ {TARGET_SCORE*100:.0f}%\")\n",
    "else:\n",
    "    print(f\"âš  Below target: {best_score*100:.1f}% < {TARGET_SCORE*100:.0f}%\")\n",
    "\n",
    "# Final diagnostics\n",
    "print(f\"\\nðŸ“Š Final Feature Profile:\")\n",
    "final_detail = detector.score_detailed(best_text)\n",
    "final_feats = final_detail['features']\n",
    "key_metrics = ['sent_len_std', 'mtld', 'ttr', 'yules_k', 'fk_grade', \n",
    "               'punct_semicolon', 'punct_apos', 'hapax_5k']\n",
    "human_avgs_key = {\n",
    "    'sent_len_std': 13.13, 'mtld': 72.83, 'ttr': 0.617, 'yules_k': 134.96,\n",
    "    'fk_grade': 14.0, 'punct_semicolon': 2.46, 'punct_apos': 1.97, 'hapax_5k': 75.89\n",
    "}\n",
    "for feat in key_metrics:\n",
    "    val = final_feats[feat]\n",
    "    hv = human_avgs_key[feat]\n",
    "    dist = abs(val - hv)\n",
    "    print(f\"  {feat:35s} = {val:8.2f}  (human: {hv:.2f}, dist: {dist:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67301f",
   "metadata": {},
   "source": [
    "## Optional: Run More Generations\n",
    "\n",
    "If the target wasn't reached, you can continue evolving from the current population.\n",
    "Each additional generation costs **1 API call**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Run additional generations if needed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Uncomment and run this cell to continue evolution\n",
    "\n",
    "# EXTRA_GENS = 3  # How many more generations to run\n",
    "# \n",
    "# # Rebuild population from the last generation's best\n",
    "# extra_pop = [h['best_text'] for h in history[-ELITE_COUNT:]]\n",
    "# while len(extra_pop) < POPULATION_SIZE:\n",
    "#     extra_pop.append(history[-1]['best_text'])\n",
    "# extra_pop = extra_pop[:POPULATION_SIZE]\n",
    "# extra_scores = detector.score_batch(extra_pop)\n",
    "# \n",
    "# # Temporarily increase generations\n",
    "# old_gens = NUM_GENERATIONS\n",
    "# NUM_GENERATIONS = EXTRA_GENS\n",
    "# best_text, best_score, extra_history = run_ga(extra_pop, extra_scores)\n",
    "# NUM_GENERATIONS = old_gens\n",
    "# \n",
    "# # Save updated output\n",
    "# with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "#     f.write(best_text)\n",
    "# history.extend(extra_history[1:])  # Skip gen 0 duplicate\n",
    "# print(f\"\\u2705 Updated output saved. New best: {best_score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8117e",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Results Summary\n",
    "\n",
    "| Phase | Best P(Human) | API Calls | Key Insight |\n",
    "|-------|--------------|-----------|-------------|\n",
    "| Original input | 0.2% | 0 | Detected as 88.4% Standard AI |\n",
    "| Initial population | 86.1% | 1 | Wild Rhythm variant jumped to 86% immediately |\n",
    "| GA generations 1-5 | 87.5% | 5 | Converged â€” mutations improved average but not peak |\n",
    "| Precision strike | **99.2%** | 1 | Vocabulary repetition was the key unlock |\n",
    "| **Total** | **99.2%** | **7** | From 0.2% to 99.2% in 7 API calls |\n",
    "\n",
    "### What This Demonstrates\n",
    "\n",
    "1. **Adversarial vulnerability**: Even a strong detector (AUC 0.9791) can be completely fooled by targeted optimization â€” from 0.2% to 99.2% Human\n",
    "2. **Feature-guided attacks are devastatingly efficient**: By diagnosing which features betray AI authorship, we craft mutations that address exact weaknesses\n",
    "3. **The GA plateau problem**: Standard GA evolution converged at ~87.5% because Gemini's \"general rewriting\" doesn't target specific statistical features\n",
    "4. **Precision beats iteration**: One targeted vocabulary-repetition prompt outperformed 5 generations of generic evolution\n",
    "\n",
    "### The Critical Insight: Vocabulary Repetition\n",
    "\n",
    "The breakthrough was understanding that **MTLD and TTR were the bottleneck**, not punctuation or sentence rhythm. The GA had already fixed:\n",
    "- Sentence length variance (5.78 â†’ 14.3)\n",
    "- Semicolons (0.0 â†’ 2.9/1k chars)\n",
    "- Apostrophes/contractions (0.0 â†’ 8.6/1k chars)\n",
    "\n",
    "But the text still scored 87.5% because **MTLD was stuck at 119** (human average: 73). AI models are trained to avoid repetition â€” the \"vocabulary smoothing\" bias identified in our analysis. The precision prompt forced word repetition (\"truth\" 6+ times, \"reality\" 4+ times), which is exactly what human philosophical writers do naturally.\n",
    "\n",
    "### Implications for AI Detection Research\n",
    "\n",
    "This experiment confirms the analysis paper's core finding: **no single detection model is sufficient**.\n",
    "\n",
    "- The **Statistician (XGBoost)** is interpretable, which makes it targetable â€” but that interpretability is what allowed us to understand the arms race\n",
    "- The **Transformer model** (AUC 0.9983) would be harder to fool since it learns latent features invisible to the attacker\n",
    "- An **ensemble approach** (combining Statistician + Transformer + Contrastive) would require the text to fool all models simultaneously\n",
    "\n",
    "### Cost Efficiency\n",
    "\n",
    "- **Total API calls**: 7 (well within the 20/day limit)\n",
    "- **Batching**: All mutations requested in single API calls per generation\n",
    "- **No retraining needed**: The detector uses pre-computed features from the training corpus\n",
    "- **Precision over brute force**: Targeted prompts >> random evolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
